# ğŸ¯ PHASE 1: FOUNDATION (3Ã—3) - `phrase1_3x3.py`

## ğŸ“¥ Input

```yaml
input_config:
  base_model: null  # Train from scratch (Phrase 1 only)
  train_dataset: "auto_generated"
  puzzle_size: 3
  load_pretrained: false
  device: "cuda" if available else "cpu"
  
validation_config:  # QUAN TRá»ŒNG: ThÃªm validation
  validation_split: 0.2  # 20% for validation
  stratified_split: true  # Äáº£m báº£o balance difficulty classes
  cross_validation: false  # KhÃ´ng cáº§n K-fold cho phrase 1
  
initialization:
  seed: 42
  weight_init: "xavier_uniform"
  custom_embeddings: false
```

---

## ğŸ“Š Dataset Structure

**Chá»§ Ä‘á»**: Giáº£i sliding puzzle 3Ã—3 cÆ¡ báº£n  
**Sá»‘ lÆ°á»£ng**: 50,000 puzzles â†’ Split: 40k train / 10k validation
**Augmentation**: 4Ã— (thay vÃ¬ 8Ã—) â†’ 160k train / 40k validation  
**Dataset**: `dataset_3x3_train.json` vÃ  `dataset_3x3_val.json`
**LÃ½ do giáº£m augmentation**: TrÃ¡nh overfitting trÃªn biáº¿n thá»ƒ tÆ°Æ¡ng tá»±

### Dataset Generation Algorithm

```python
def generate_3x3_dataset():
    """
    1. Báº¯t Ä‘áº§u tá»« solved state: [[1,2,3], [4,5,6], [7,8,0]]
    2. Random shuffle: 5-20 moves há»£p lá»‡
    3. Check solvability: inversion count
    4. Solve vá»›i A* + Manhattan distance
    5. Record optimal path
    6. Augment: 8 biáº¿n thá»ƒ (rot + flip)
    """
```

### Dataset Schema

```json
{
  "version": "1.0",
  "phrase": 1,
  "puzzle_size": 3,
  "data": [
    {
      "id": "p1_001",
      "initial_state": [[7,2,4], [5,0,6], [8,3,1]],
      "solved_state": [[1,2,3], [4,5,6], [7,8,0]],
      "optimal_path": ["up", "left", "down", "right", "up"],
      "num_moves": 5,
      "difficulty_class": 0,
      "metadata": {
        "manhattan_distance": 12,
        "linear_conflict": 2,
        "solvable": true,
        "generation_method": "random_walk",
        "solver": "A*"
      }
    }
  ]
}
```

---

## ğŸ—ï¸ Model Architecture

### Network Structure

```yaml
model_architecture:
  input_shape: [3, 3, 13]  # (rows, cols, channels)
  # Channels: 9 one-hot (tiles 1-9) + 4 features (empty_pos_x, empty_pos_y, parity, normalized_state)
  
  input_layer:
    - Flatten: (3, 3, 13) â†’ 117
    - BatchNorm1d: 117
  
  encoder_layers:
    - name: "encoder.0"
      type: Linear
      in_features: 117
      out_features: 256
      activation: ReLU
      dropout: 0.0
      
    - name: "encoder.1"
      type: Linear
      in_features: 256
      out_features: 128
      activation: ReLU
      dropout: 0.0
      
    - name: "encoder.2"
      type: Linear
      in_features: 128
      out_features: 64
      activation: ReLU
      dropout: 0.0
  
  heads:
    policy_head:
      - name: "policy.0"
        type: Linear
        in_features: 64
        out_features: 128  # TÄƒng capacity
        activation: ReLU
        dropout: 0.2  # TÄƒng dropout
        batch_norm: true  # ThÃªm BatchNorm
        
      - name: "policy.1"
        type: Linear
        in_features: 128
        out_features: 4
        activation: Softmax
        note: "4 directions: up, down, left, right"
        temperature_scaling: true  # ThÃªm temperature Ä‘á»ƒ control confidence
    
    value_head:  # OPTIONAL: Chá»‰ cáº§n cho puzzle 8x8+
      - name: "value.0"
        type: Linear
        in_features: 64
        out_features: 32  # Giáº£m complexity
        activation: ReLU
        
      - name: "value.1"
        type: Linear
        in_features: 32
        out_features: 1
        activation: Linear  # Thay Tanh = Linear + MSE loss
        note: "Predict steps-to-solve (chá»‰ train tá»« phrase 4+)"
```

---

## ğŸ“ Training Configuration

```yaml
training_config:
  algorithm: "Supervised Learning"
  
  hyperparameters:
    learning_rate: 0.0005  # Giáº£m tá»« 0.001
    batch_size: 256  # TÄƒng tá»« 128 (A100 80GB Ä‘á»§)
    gradient_accumulation_steps: 1
    num_epochs: 100  # Giáº£m tá»« 200
    max_length: null  # Not applicable for puzzle
    warmup_steps: 500  # ThÃªm warmup
    warmup_method: "linear"
    weight_decay: 1e-4  # ThÃªm regularization
    max_grad_norm: 1.0
    label_smoothing: 0.1  # ThÃªm label smoothing cho policy
    
  optimizer:
    type: "Adam"
    betas: [0.9, 0.999]
    eps: 1e-8
    
  scheduler:
    type: "CosineAnnealingWarmRestarts"  # Thay ReduceLROnPlateau
    T_0: 10  # Restart every 10 epochs
    T_mult: 2  # Double period after each restart
    eta_min: 1e-6
    
  early_stopping:  # QUAN TRá»ŒNG: ThÃªm early stopping
    enabled: true
    monitor: "val_loss"
    patience: 15
    min_delta: 0.001
    restore_best_weights: true
    
  losses:
    policy_loss:
      type: "CrossEntropyLoss"
      weight: 1.0
      label_smoothing: 0.1  # ThÃªm smoothing
      note: "Predict next optimal move"
      
    value_loss:
      type: "MSELoss"
      weight: 0.3  # Giáº£m tá»« 0.5
      note: "Predict steps-to-solve (optional cho 3x3)"
      enabled_from_phrase: 4  # Chá»‰ enable tá»« phrase 4 (6x6)
      
    # REMOVED: difficulty_loss - KhÃ´ng cáº§n thiáº¿t
  
  total_loss: "lambda_policy * policy_loss + lambda_value * value_loss + lambda_difficulty * difficulty_loss"
  
  gradient_clipping:
    enabled: true
    max_norm: 1.0
    
  seed: 42
  deterministic: true
```

### Data Augmentation

```yaml
augmentation:
  enabled: true
  multiplier: 4x  # 40k â†’ 160k samples (giáº£m tá»« 8x)
  apply_to_validation: false  # QUAN TRá»ŒNG: KhÃ´ng augment validation set
  
  methods:  # Chá»‰ giá»¯ 3 augmentations chÃ­nh
    - rotation_90: "Rotate puzzle 90Â° clockwise + transform actions"
    - rotation_180: "Rotate puzzle 180Â°"
    - flip_horizontal: "Mirror horizontally + swap left/right actions"
    # REMOVED: CÃ¡c combinations phá»©c táº¡p â†’ Dá»… overfit
  
  synchronization: "Actions transformed consistently with state"
  
  additional_techniques:
    random_noise: 
      enabled: false  # KhÃ´ng Ã¡p dá»¥ng cho puzzle (discrete state)
    mixup:
      enabled: false  # KhÃ´ng phÃ¹ há»£p vá»›i classification
```

### Validation Strategy

```yaml
validation:
  split: 0.2  # QUAN TRá»ŒNG: 20% validation (thay vÃ¬ 0.0)
  stratified: true  # Balance difficulty distribution
  
  evaluation:
    frequency: "every_epoch"  # Validate sau má»—i epoch
    method: "solve_validation_puzzles"
    validation_set_size: 10000  # Full validation set
    
    metrics:
      primary:
        - val_policy_accuracy: "Accuracy of next move prediction"
        - val_solve_rate: "Percentage of puzzles solved"
        - val_optimal_path_rate: "Percentage matching optimal solution"
        
      secondary:
        - val_value_mae: "MAE on steps-to-solve prediction"
        - val_loss: "Combined validation loss"
        - train_val_gap: "Overfitting indicator"
        
      monitoring:
        - solve_rate_threshold: 0.95  # Stop if < 95%
        - overfit_threshold: 0.15  # Stop if train-val gap > 15%
        
  test_set:  # ThÃªm separate test set
    enabled: true
    size: 5000  # Hold-out test set
    evaluate_at: "end_of_phrase"
    final_benchmark: true
```

---

## ğŸ“¤ Output Structure (Extended)

```
phrase1_output_3x3.zip/phrase1_output/
â”œâ”€â”€ models/                              # Model checkpoints chÃ­nh
â”‚   â”œâ”€â”€ numpuz_3x3_best.pth              # â­ QUAN TRá»ŒNG - Best model (dÃ¹ng cho Phrase 2)
â”‚   â”œâ”€â”€ model_architecture.json          # Kiáº¿n trÃºc model chi tiáº¿t
â”‚   â””â”€â”€ optimizer_state.pth              # Optimizer state (optional backup)
â”‚
â”œâ”€â”€ gguf_models/                         # GGUF quantized models (deployment-ready)
â”‚   â”œâ”€â”€ numpuz_3x3_q4_0.gguf             # 4-bit quantization (nháº¹ nháº¥t, má»¥c tiÃªu cuá»‘i)
â”‚   â”œâ”€â”€ numpuz_3x3_q5_1.gguf             # 5-bit quantization (cÃ¢n báº±ng)
â”‚   â”œâ”€â”€ numpuz_3x3_q8_0.gguf             # 8-bit quantization (cháº¥t lÆ°á»£ng cao)
â”‚   â”œâ”€â”€ numpuz_3x3_f16.gguf              # Full 16-bit (cháº¥t lÆ°á»£ng tá»‘t nháº¥t)
â”‚   â””â”€â”€ gguf_conversion_log.txt          # Log quÃ¡ trÃ¬nh convert sang GGUF
â”‚
â”œâ”€â”€ visualizations/                      # PNG charts Ä‘á»ƒ xem trá»±c quan
â”‚   â”œâ”€â”€ loss_curves_3x3.png             # Training loss (policy + value + difficulty)
â”‚   â”œâ”€â”€ accuracy_curves_3x3.png          # Policy accuracy, difficulty accuracy
â”‚   â”œâ”€â”€ value_mae_curve_3x3.png          # Value prediction MAE over epochs
â”‚   â”œâ”€â”€ learning_rate_schedule_3x3.png   # Learning rate changes
â”‚   â”œâ”€â”€ gradient_norm_3x3.png            # Gradient norm tracking
â”‚   â”œâ”€â”€ solve_rate_evolution_3x3.png     # Solve rate improvement over training
â”‚   â”œâ”€â”€ difficulty_distribution_3x3.png  # Distribution of puzzle difficulties
â”‚   â”œâ”€â”€ moves_histogram_3x3.png          # Histogram of solution lengths
â”‚   â”œâ”€â”€ training_speed_3x3.png           # Samples/second over epochs
â”‚   â””â”€â”€ gpu_memory_usage_3x3.png         # VRAM usage tracking
â”‚
â”œâ”€â”€ training_logs/                       # Logs chi tiáº¿t
â”‚   â””â”€â”€ training_history_3x3.json        # Metrics qua táº¥t cáº£ epochs
â”‚
â”œâ”€â”€ evaluation/                          # Káº¿t quáº£ Ä‘Ã¡nh giÃ¡
â”‚   â”œâ”€â”€ test_results_3x3.json            # Káº¿t quáº£ test trÃªn 1000 puzzles
â”‚   â”œâ”€â”€ solve_rate_breakdown.json        # Solve rate theo difficulty class
â”‚   â”œâ”€â”€ optimal_path_comparison.json     # So sÃ¡nh vá»›i A* optimal
â”‚   â”œâ”€â”€ value_prediction_errors.json     # Chi tiáº¿t lá»—i value prediction
â”‚   â”œâ”€â”€ confusion_matrix_difficulty.png  # Confusion matrix difficulty classification
â”‚   â”œâ”€â”€ policy_heatmap.png               # Heatmap policy distribution
â”‚   â””â”€â”€ benchmark_results.json           # Benchmark vá»›i cÃ¡c baselines
â”‚
â”œâ”€â”€ exports/                             # Export formats khÃ¡c
â”‚   â”œâ”€â”€ numpuz_3x3.onnx                  # ONNX format (cross-platform)
â”‚   â”œâ”€â”€ numpuz_3x3_torchscript.pt        # TorchScript format
â”‚   â”œâ”€â”€ numpuz_3x3_openvino/             # OpenVINO IR format
â”‚   â””â”€â”€ export_config.json               # Export configuration
â”‚
â””â”€â”€ configs/                             # Configuration backups
    â”œâ”€â”€ train_config_3x3.yaml            # Full training config
    â”œâ”€â”€ model_config_3x3.json            # Model architecture config
    â”œâ”€â”€ dataset_config_3x3.json          # Dataset generation config
    â””â”€â”€ augmentation_config_3x3.json     # Augmentation settings